{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f6980e52",
      "metadata": {
        "id": "f6980e52"
      },
      "source": [
        "# `Sign Language Prediction using ResNet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f4dc43",
      "metadata": {
        "id": "f4f4dc43"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import os\n",
        "import cv2\n",
        "#import imghdr\n",
        "#import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.applications import ResNet50\n",
        "from sklearn.preprocessing import normalize\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "#----------------\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D, Dense,Flatten, Dropout\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400b6d88",
      "metadata": {
        "id": "400b6d88",
        "outputId": "cc0826fc-9482-4af3-ab7d-acfd311665c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bye', 'drink', 'eat', 'hello', 'help', 'love', 'morning', 'okay', 'please', 'stop', 'thankyou']\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data_path = 'Dataset\\Signs'\n",
        "high_level_directory = os.listdir(data_path)\n",
        "\n",
        "# List to store image paths and corresponding labels\n",
        "images = []\n",
        "labels = []\n",
        "classes=[]\n",
        "\n",
        "for class_name in high_level_directory:\n",
        "    classes.append(class_name)\n",
        "    class_path = os.path.join(data_path, class_name)\n",
        "    for image_name in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "        resized_img=cv2.resize(img,(224,224))\n",
        "        images.append(resized_img)\n",
        "        labels.append(class_name)\n",
        "\n",
        "\n",
        "print(high_level_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e203fdb0",
      "metadata": {
        "id": "e203fdb0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels,stratify=labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7a56da",
      "metadata": {
        "id": "7f7a56da",
        "outputId": "380ba46c-1a3b-4786-857d-72a14078b648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955ea8b6",
      "metadata": {
        "id": "955ea8b6",
        "outputId": "7c627661-5b4f-41a7-d64b-a7a5a0ef1030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ac6126",
      "metadata": {
        "id": "72ac6126",
        "outputId": "b0d266b1-d1a4-43a7-bed3-7f96bc69997f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "753"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9669f4c2",
      "metadata": {
        "id": "9669f4c2",
        "outputId": "4ac5f945-66ac-4fbe-d204-e498d7c4567e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcc51c9",
      "metadata": {
        "id": "ebcc51c9"
      },
      "source": [
        "## ResNet Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de7fa86",
      "metadata": {
        "id": "7de7fa86"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540dd950",
      "metadata": {
        "id": "540dd950",
        "outputId": "02acc32a-88f2-4924-ea76-b50aaed242ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 942 files belonging to 10 classes.\n",
            "Using 754 files for training.\n",
            "Using 188 files for validation.\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "train_dir = data_path\n",
        "\n",
        "train_data, test_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                                label_mode=\"categorical\",\n",
        "                                                                                image_size=IMG_SIZE,\n",
        "                                                                                validation_split=0.2,\n",
        "                                                                                seed = 42,\n",
        "                                                                                batch_size=32,\n",
        "                                                                                subset=\"both\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acab0313",
      "metadata": {
        "id": "acab0313",
        "outputId": "406c79f4-14cf-470c-cd47-67953cacdabe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "\n",
        "# Create base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = layers.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(classes))(x) # want one output neuron per class\n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e7f67a",
      "metadata": {
        "id": "e5e7f67a",
        "outputId": "ed39e909-067f-47c5-c0e9-226ba46b2e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
            " )                           )                                   \n",
            "                                                                 \n",
            " pooling_layer (GlobalAvera  (None, 1280)              0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                12810     \n",
            "                                                                 \n",
            " softmax_float32 (Activatio  (None, 10)                0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4062381 (15.50 MB)\n",
            "Trainable params: 12810 (50.04 KB)\n",
            "Non-trainable params: 4049571 (15.45 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d093f56d",
      "metadata": {
        "id": "d093f56d",
        "outputId": "6a33f7a7-3e0d-4e1c-ca05-d35f7d977f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 29s 983ms/step - loss: 2.0960 - accuracy: 0.2546\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 28s 1s/step - loss: 1.5989 - accuracy: 0.6273\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 27s 1s/step - loss: 1.2790 - accuracy: 0.7427\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 25s 1s/step - loss: 1.0781 - accuracy: 0.7958\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 26s 1s/step - loss: 0.9250 - accuracy: 0.8448\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 25s 1000ms/step - loss: 0.8083 - accuracy: 0.8607\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 26s 1s/step - loss: 0.7246 - accuracy: 0.8727\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 21s 875ms/step - loss: 0.6487 - accuracy: 0.9125\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 21s 858ms/step - loss: 0.5838 - accuracy: 0.9271\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 21s 859ms/step - loss: 0.5361 - accuracy: 0.9324\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 21s 847ms/step - loss: 0.4934 - accuracy: 0.9416\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 21s 852ms/step - loss: 0.4554 - accuracy: 0.9496\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 21s 850ms/step - loss: 0.4185 - accuracy: 0.9629\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 21s 848ms/step - loss: 0.3915 - accuracy: 0.9655\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 22s 927ms/step - loss: 0.3652 - accuracy: 0.9668\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 22s 886ms/step - loss: 0.3412 - accuracy: 0.9708\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.3197 - accuracy: 0.9721\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 22s 886ms/step - loss: 0.3019 - accuracy: 0.9788\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 22s 886ms/step - loss: 0.2862 - accuracy: 0.9775\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 22s 885ms/step - loss: 0.2693 - accuracy: 0.9828\n"
          ]
        }
      ],
      "source": [
        "# Turn off all warnings except for errors\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Fit the model with callbacks\n",
        "history_101_food_classes_feature_extract = model.fit(train_data,\n",
        "                                                     epochs=20,\n",
        "                                                     steps_per_epoch=len(train_data),\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps=int(0.15 * len(test_data)),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf5828c",
      "metadata": {
        "id": "acf5828c",
        "outputId": "405bbb65-a488-42ff-adb4-abb87779bb13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 7s 929ms/step - loss: 0.5880 - accuracy: 0.8351\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5879871845245361, 0.835106372833252]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_model = model.evaluate(test_data)\n",
        "result_model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}